{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Description\n",
    "This part of the project focuses on identifying useful features for obtaining an adequate forecasting model  for TSD. Feature engineering and model training has been combined into a cyclic process to check the effects of feartures on model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Relevant Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose, DecomposeResult\n",
    "from src.features.feature_utils import create_lag_features, plot_correlation_matrix, plot_seasonal_decompose\n",
    "from src.features.feature_utils import plot_acf_and_pacf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('../'))\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = sys.path[-1]\n",
    "project_root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../data/interim/uk_data_processed_postEDA.pkl\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Trends and Seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = seasonal_decompose(df['tsd'], model='additive', period=365*48)\n",
    "df.set_index('date', inplace=True)\n",
    "fig = plot_seasonal_decompose(result, dates=df.index, target_name='tsd')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_acf, fig_pacf = plot_acf_and_pacf(df['tsd'], lags=336)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_acf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_pacf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('date', inplace=True)\n",
    "proc_fe_df = create_lag_features(df, save_data=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_fe_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from src.models.model_utils import model_evaluator, model_feature_importance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_df = pd.read_pickle(\"../data/processed/uk_data_fe_processed.pkl\")\n",
    "fe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fe_df = fe_df[['tsd', 'lag_1day', 'lag_1hour', 'lag_1week', 'lag_1year', 'lag_2year', 'rolling_mean_1day']]\n",
    "fig = plot_correlation_matrix(fe_df)\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation matrix suggests 5 features:<br>\n",
    "1. lag48 - 1 day shift \n",
    "2. lag336 - 1 week shift\n",
    "3. lag1yr - 1 year shift \n",
    "4. rolling_mean_48  \n",
    "5. lag2yr - 2 year shift \n",
    "\n",
    "This reduces the number of features considered from 12 (initial for gradient boost model fold 5) which had added benefit of faster model training, and less redundacy. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I drop:<br>\n",
    "1. temporal features, period, days, weeks, months, etc they have been poor in earlier gradient boost and recent modeling in this notebook. Corr matrix also shows poor correlation. \n",
    "2. rolling_std_48: its highly co-linear with rolling_mean_48 but poorly corr with tsd\n",
    "3. lag3yr: similar reason as 2 above\n",
    "4. lag5yr: similar reason as 2 above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "px.line(fe_df, x=fe_df.index, y=['tsd', \n",
    "                                 'lag_1hour','lag_1day','lag_1week','lag_1year','lag_2year','rolling_mean_1day'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "features = [\n",
    "    'lag_1day', 'lag_1hour', 'lag_1week', 'lag_1year', 'lag_2year', 'rolling_mean_1day'\n",
    "]\n",
    "target = 'tsd'\n",
    "fe_df = fe_df.sort_index()\n",
    "X = fe_df[features].dropna()\n",
    "y = fe_df[target].dropna().loc[X.index]         \n",
    " \n",
    "# Define models\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "xgb_model = XGBRegressor(n_estimators=100,random_state=42)\n",
    "\n",
    "# Stores for model outputs \n",
    "rf_results = []\n",
    "gb_results = []\n",
    "xgb_results = []\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Create time-series split cross validation\n",
    "tscv = TimeSeriesSplit(n_splits=5, test_size =48*365*1, gap=48)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loop through the folds...\n",
    "for fold, (train_idx, test_idx) in enumerate(tscv.split(X), start=1):\n",
    "    print(f\"Running Fold {fold}...\")\n",
    "    print('Spliting data into training and testing data subsets...')\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "               \n",
    "    # Run Models\n",
    "    try:\n",
    "        # Random Forest\n",
    "        print('Running Random Forest model...')\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        rf_pred = rf_model.predict(X_test)\n",
    "        rf_results.append(model_evaluator(fold, y_test, rf_pred, rf_model, 'random_forest'))  \n",
    "    except Exception as e:\n",
    "        print(f\"Random Forest model failed on fold {fold}: {e}\")\n",
    "        \n",
    "    try:\n",
    "        # Gradient Boosting\n",
    "        print('Running Gradient Boost model...')\n",
    "        gb_model.fit(X_train, y_train)\n",
    "        gb_pred = gb_model.predict(X_test)\n",
    "        gb_results.append(model_evaluator(fold, y_test, gb_pred, gb_model, 'gradient_boost'))   \n",
    "    except Exception as e:\n",
    "        print(f\"Gradient Boostng model failed on fold {fold}: {e}\")\n",
    "        \n",
    "    try:\n",
    "        # XGBoost\n",
    "        print('Running XGBoost model...')\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "        xgb_pred = xgb_model.predict(X_test)\n",
    "        xgb_results.append(model_evaluator(fold, y_test, xgb_pred, xgb_model, 'xgboost'))\n",
    "    except Exception as e:\n",
    "        print(f\"XGBoost model failed on fold {fold}: {e}\")\n",
    "          \n",
    "# Model training complete\n",
    "print('Model training complete')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random forest model fold 5   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Model\n",
    "best_model_vars = rf_results[-1]   # best model - rf_model fold 1 \n",
    "best_model_02_vars = xgb_results[-1]  # 2nd best model - xgb_model fold 5\n",
    "print(f\"Result of the best model:{best_model_vars}\")\n",
    "print(f\"Result of the 2nd best model:{best_model_02_vars}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance - Best Model...\n",
    "print('Generating feature importance from best model')\n",
    "_ , fig = model_feature_importance(X,best_model_vars)\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Generating feature importance from 2nd best model')\n",
    "_ , fig = model_feature_importance(X,best_model_02_vars)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_actual_vs_model_pred(model_vars, X, y):\n",
    "    \"\"\"\n",
    "    This function plots a comparison on the actual and predicted data for model verification.\n",
    "     \n",
    "    Args:\n",
    "    model_vars:         a dictionary containing the variables of the best trained model\n",
    "    X:                  the features that was used for training the best model\n",
    "    y:                  the target that was used for training the best model\n",
    "    Return:\n",
    "    fig:                the plotly plot output\n",
    "    \n",
    "    \"\"\"\n",
    "    train_set = 0\n",
    "    test_set = 1\n",
    "    \n",
    "    \n",
    "    fold_ct = model_vars['fold'] - 1 # 0, 1, 2, 3, or 4 representing fold 1, 2, 3, 4 or 5 respectively \n",
    "    scope_test_idx = list(tscv.split(X))[fold_ct][test_set]\n",
    "    X_scope_test = X.iloc[scope_test_idx]\n",
    "    y_scope_test = y.iloc[scope_test_idx]\n",
    "    \n",
    "    model_pred = model_vars['model'].predict(X_scope_test)\n",
    "    fig = px.line(title=f\"Actual vs Predicted TSD from fold {model_vars['fold']}\")\n",
    "    fig.add_scatter(y=y_scope_test.values, mode='lines', name='Actual')\n",
    "    fig.add_scatter(y=model_pred, mode='lines', name=f\"{model_vars['model_name']} Predicted\")\n",
    "    fig.update_layout(yaxis_title='Transmission Systems Demand (MW)')\n",
    "    \n",
    "    return fig\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vars = best_model_vars\n",
    "fig = plot_actual_vs_model_pred(model_vars, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vars = best_model_02_vars\n",
    "fig = plot_actual_vs_model_pred(model_vars, X, y)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model and its performance metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pickle\n",
    "\n",
    "\n",
    "joblib.dump(best_model_vars['model'], f\"{project_root}/models/{best_model_vars['model_name']}_best_model.pkl\")\n",
    "joblib.dump(best_model_02_vars['model'], f\"{project_root}/models/{best_model_02_vars['model_name']}_2nd_best_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternate - save model and its metrics \n",
    "best_01_and_02_models = [best_model_vars,best_model_02_vars]\n",
    "\n",
    "model_save_filepath = f\"{project_root}/models/best_rf_and_xgb_models.pkl\"\n",
    "with open(model_save_filepath, 'wb') as file:\n",
    "    pickle.dump(best_01_and_02_models, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load the models\n",
    "with open(model_save_filepath,'rb') as file:\n",
    "    loaded_models = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_model_vars = loaded_models[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_model_vars['model_name']\n",
    "float(ml_model_vars['MAE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'model_name': ml_model_vars['model_name'],\n",
    "            'MAE': [float(ml_model_vars['MAE'])],\n",
    "            'RMSE': [float(ml_model_vars['RMSE'])],\n",
    "            'MAPE': [float(ml_model_vars['MAPE'])]\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
